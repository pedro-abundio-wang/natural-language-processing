{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning & Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/adam.png)\n",
    "![](imgs/dropout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Transition-Based Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/parse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/batch-parse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIFT test passed!\n",
      "LEFT-ARC test passed!\n",
      "RIGHT-ARC test passed!\n",
      "parse test passed!\n"
     ]
    }
   ],
   "source": [
    "from parser_transitions import *\n",
    "from parser_model import *\n",
    "\n",
    "test_parse_step()\n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch_parse test passed!\n"
     ]
    }
   ],
   "source": [
    "test_minibatch_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/nn-alg.png)\n",
    "![](imgs/debug.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.parser_utils import minibatches, load_and_preprocess_data, AverageMeter\n",
    "\n",
    "# -----------------\n",
    "# Primary Functions\n",
    "# -----------------\n",
    "def train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005):\n",
    "    \"\"\" Train the neural dependency parser.\n",
    "\n",
    "    @param parser (Parser): Neural Dependency Parser\n",
    "    @param train_data ():\n",
    "    @param dev_data ():\n",
    "    @param output_path (str): Path to which model weights and results are written.\n",
    "    @param batch_size (int): Number of examples in a single batch\n",
    "    @param n_epochs (int): Number of training epochs\n",
    "    @param lr (float): Learning rate\n",
    "    \"\"\"\n",
    "    best_dev_UAS = 0\n",
    "\n",
    "    \n",
    "    ### YOUR CODE HERE (~2-7 lines)\n",
    "    ### TODO:\n",
    "    ###      1) Construct Adam Optimizer in variable `optimizer`\n",
    "    ###      2) Construct the Cross Entropy Loss Function in variable `loss_func`\n",
    "    ###\n",
    "    ### Hint: Use `parser.model.parameters()` to pass optimizer\n",
    "    ###       necessary parameters to tune.\n",
    "    ### Please see the following docs for support:\n",
    "    ###     Adam Optimizer: https://pytorch.org/docs/stable/optim.html\n",
    "    ###     Cross Entropy Loss: https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "    optimizer = optim.Adam(parser.model.parameters(), lr=lr)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {:} out of {:}\".format(epoch + 1, n_epochs))\n",
    "        dev_UAS = train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size)\n",
    "        if dev_UAS > best_dev_UAS:\n",
    "            best_dev_UAS = dev_UAS\n",
    "            print(\"New best dev UAS! Saving model.\")\n",
    "            torch.save(parser.model.state_dict(), output_path)\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "def train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size):\n",
    "    \"\"\" Train the neural dependency parser for single epoch.\n",
    "\n",
    "    Note: In PyTorch we can signify train versus test and automatically have\n",
    "    the Dropout Layer applied and removed, accordingly, by specifying\n",
    "    whether we are training, `model.train()`, or evaluating, `model.eval()`\n",
    "\n",
    "    @param parser (Parser): Neural Dependency Parser\n",
    "    @param train_data ():\n",
    "    @param dev_data ():\n",
    "    @param optimizer (nn.Optimizer): Adam Optimizer\n",
    "    @param loss_func (nn.CrossEntropyLoss): Cross Entropy Loss Function\n",
    "    @param batch_size (int): batch size\n",
    "    @param lr (float): learning rate\n",
    "\n",
    "    @return dev_UAS (float): Unlabeled Attachment Score (UAS) for dev data\n",
    "    \"\"\"\n",
    "    parser.model.train() # Places model in \"train\" mode, i.e. apply dropout layer\n",
    "    n_minibatches = math.ceil(len(train_data) / batch_size)\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(n_minibatches)) as prog:\n",
    "        for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):\n",
    "            optimizer.zero_grad()   # remove any baggage in the optimizer\n",
    "            loss = 0. # store loss for this batch here\n",
    "            train_x = torch.from_numpy(train_x).long()\n",
    "            train_y = torch.from_numpy(train_y.nonzero()[1]).long()\n",
    "\n",
    "            ### YOUR CODE HERE (~5-10 lines)\n",
    "            ### TODO:\n",
    "            ###      1) Run train_x forward through model to produce `logits`\n",
    "            ###      2) Use the `loss_func` parameter to apply the PyTorch CrossEntropyLoss function.\n",
    "            ###         This will take `logits` and `train_y` as inputs. It will output the CrossEntropyLoss\n",
    "            ###         between softmax(`logits`) and `train_y`. Remember that softmax(`logits`)\n",
    "            ###         are the predictions (y^ from the PDF).\n",
    "            ###      3) Backprop losses\n",
    "            ###      4) Take step with the optimizer\n",
    "            ### Please see the following docs for support:\n",
    "            ###     Optimizer Step: https://pytorch.org/docs/stable/optim.html#optimizer-step\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = parser.model(train_x)\n",
    "            loss = loss_func(outputs, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ### END YOUR CODE\n",
    "            prog.update(1)\n",
    "            loss_meter.update(loss.item())\n",
    "\n",
    "    print (\"Average Train Loss: {}\".format(loss_meter.avg))\n",
    "\n",
    "    print(\"Evaluating on dev set\",)\n",
    "    parser.model.eval() # Places model in \"eval\" mode, i.e. don't apply dropout layer\n",
    "    dev_UAS, _ = parser.parse(dev_data)\n",
    "    print(\"- dev UAS: {:.2f}\".format(dev_UAS * 100.0))\n",
    "    return dev_UAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIALIZING\n",
      "================================================================================\n",
      "Loading data...\n",
      "took 2.17 seconds\n",
      "Building parser...\n",
      "took 1.15 seconds\n",
      "Loading pretrained embeddings...\n",
      "took 2.40 seconds\n",
      "Vectorizing data...\n",
      "took 1.70 seconds\n",
      "Preprocessing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 50.00 seconds\n",
      "took 0.07 seconds\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [06:16<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.18312669072090548\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 40393888.22it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 84.26\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [06:09<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.11557890887642319\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 36783637.75it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 86.40\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [05:59<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.10130425278315103\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 35356839.74it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 87.07\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [05:43<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.09287279845896737\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 36521354.77it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 87.71\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [06:03<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.08607277764184844\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 36483344.19it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.04\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [05:45<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.08136206297042631\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 36184243.29it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.25\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [06:02<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.07693443392318758\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 39922413.90it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.58\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [05:56<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.07320616774470647\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 40216286.16it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.44\n",
      "\n",
      "Epoch 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [06:02<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.07000913680430292\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 36715046.88it/s]      \n",
      "  0%|          | 0/1848 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.79\n",
      "New best dev UAS! Saving model.\n",
      "\n",
      "Epoch 10 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1848/1848 [05:56<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 0.06716169053245158\n",
      "Evaluating on dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1445850it [00:00, 40742066.94it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dev UAS: 88.49\n",
      "\n",
      "================================================================================\n",
      "TESTING\n",
      "================================================================================\n",
      "Restoring the best model weights found on the dev set\n",
      "Final evaluation on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2919736it [00:00, 41040571.81it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- test UAS: 88.94\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: Set debug to False, when training on entire corpus\n",
    "# debug = True\n",
    "debug = False\n",
    "\n",
    "print(80 * \"=\")\n",
    "print(\"INITIALIZING\")\n",
    "print(80 * \"=\")\n",
    "parser, embeddings, train_data, dev_data, test_data = load_and_preprocess_data(debug)\n",
    "\n",
    "start = time.time()\n",
    "model = ParserModel(embeddings)\n",
    "parser.model = model\n",
    "print(\"took {:.2f} seconds\\n\".format(time.time() - start))\n",
    "\n",
    "print(80 * \"=\")\n",
    "print(\"TRAINING\")\n",
    "print(80 * \"=\")\n",
    "output_dir = \"results/{:%Y%m%d_%H%M%S}/\".format(datetime.now())\n",
    "output_path = output_dir + \"model.weights\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "train(parser, train_data, dev_data, output_path, batch_size=1024, n_epochs=10, lr=0.0005)\n",
    "\n",
    "if not debug:\n",
    "    print(80 * \"=\")\n",
    "    print(\"TESTING\")\n",
    "    print(80 * \"=\")\n",
    "    print(\"Restoring the best model weights found on the dev set\")\n",
    "    parser.model.load_state_dict(torch.load(output_path))\n",
    "    print(\"Final evaluation on test set\",)\n",
    "    parser.model.eval()\n",
    "    UAS, dependencies = parser.parse(test_data)\n",
    "    print(\"- test UAS: {:.2f}\".format(UAS * 100.0))\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/relation.png)\n",
    "![](imgs/error.png)\n",
    "![](imgs/structure.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
