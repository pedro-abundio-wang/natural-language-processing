# Natural Language Processing with Deep Learning

## Word Vectors

### Word2Vec

#### Papers

[Bengio et al., 2003] A neural probabilistic language model.

[Collobert et al., 2011] Natural language processing (almost) from scratch.

[Mikolov et al., 2013] Efficient estimation of word representations in vector space. (original word2vec paper)

[Rong et al., 2014] word2vec parameter learning explained.

[Tomas et al., 2013] Distributed Representations of Words and Phrases and their Compositionality (negative sampling paper)

#### Math

[Singular Value Decomposition Tutorial](https://davetang.org/file/Singular_Value_Decomposition_Tutorial.pdf)

#### Reading



### GloVe

#### Papers

[Pennington et al., 2014] GloVe: Global vectors for word representation (original GloVe paper)

[Yin et al., 2018] On the Dimensionality of Word Embedding

[Huang et al., 2012] Improving Word Representations Via Global Context And Multiple Word Prototypes
